{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: For Prototype OK to import whole library, otherwise only import necessary modules\n",
    "\n",
    "import cv2 \n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals: \n",
    "\n",
    "- Create a prototype OCR \n",
    "\n",
    "#### Minimal functions: \n",
    "\n",
    "- Parse a Folder with images\n",
    "- Preprocess each image \n",
    "- Run OCR on each image \n",
    "- Store image name and text found in a DataFrame\n",
    "- Convert DataFrame to CSV for further processing / upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#find only images with jpg, jpeg and png ending\n",
    "def is_image(filename):\n",
    "    if file.lower().endswith(('.jpg', '.jpeg','.png')):\n",
    "            return file\n",
    "\n",
    "\n",
    "#resize image\n",
    "def scale_image(pct, img):\n",
    "    scale_percent = pct # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized\n",
    "  \n",
    "\n",
    "\n",
    "### Iamge corrections from: https://nanonets.com/blog/ocr-with-tesseract/\n",
    "\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,3)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment with different components of the pipeline to get best results\n",
    "\n",
    "def processing_pipeline(src_path):\n",
    "    image = cv2.imread(src_path)\n",
    "    image = scale_image(150, image)\n",
    "    image = get_grayscale(image) #convert image to Greyscale\n",
    "    image = remove_noise(image) #remove noise\n",
    "    image = thresholding(image) #Threshholding\n",
    "    image = canny(image) #canny edge detection\n",
    "    image = deskew(image)  #deskew\n",
    "    return image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the images\n",
    "\n",
    "image_filenames = [] #list for image filenames\n",
    "extracted_text = [] #list for extracted text\n",
    "\n",
    "image_folder = \"./images\" #where the images are stored for prototype\n",
    "\n",
    "for root, directories, files in os.walk(image_folder): #iterate through file system\n",
    "    for file in files:\n",
    "        if is_image(file):\n",
    "            src_path = os.path.join(root,file) #this only works without subdirectories\n",
    "            processed_image = processing_pipeline(src_path) #process the images with image processing pipeline\n",
    "            processed_data = pytesseract.image_to_string(processed_image,  lang='eng') #extract english text from images \n",
    "            image_filenames.append(src_path) #append filenames\n",
    "            extracted_text.append(processed_data) #append text\n",
    "\n",
    "raw_data = zip(image_filenames, extracted_text) #combine image filenames with extracted text\n",
    "df = pd.DataFrame(raw_data, columns=['image_filenamme','extracted_text']) #convert to dataframe \n",
    "df.to_csv('extracted_information.csv') #save csv to disk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
